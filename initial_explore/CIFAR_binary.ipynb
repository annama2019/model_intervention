{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as nnf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timm\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import ConcatDataset\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms as T\n",
    "from torch.nn.functional import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cifar10_train = datasets.CIFAR10(\"../data\", train=True, download=True, transform=T.ToTensor())\n",
    "cifar10_test = datasets.CIFAR10(\"../data\", train=False, download=True, transform=T.ToTensor())\n",
    "my_model = timm.create_model('resnet18',pretrained = False).cuda()\n",
    "num_ftrs = my_model.fc.in_features\n",
    "my_model.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "train_cats=torch.cat([cifar10_train[i][0][None,:,:,:] for i in range(50000) if cifar10_train[i][1]==3])\n",
    "train_dogs=torch.cat([cifar10_train[i][0][None,:,:,:] for i in range(50000) if cifar10_train[i][1]==5])[:1000]\n",
    "test_cats=torch.cat([cifar10_test[i][0][None,:,:,:] for i in range(10000) if cifar10_test[i][1]==3])\n",
    "test_dogs=torch.cat([cifar10_test[i][0][None,:,:,:] for i in range(10000) if cifar10_test[i][1]==5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BinaryDataset(Dataset):\n",
    "    def __init__(self, class1, class2, transform=None, target_transform=None):\n",
    "        self.imgs = torch.cat([class1,class2])\n",
    "        self.img_labels = [0 for _ in range(len(class1))]+[1 for _ in range(len(class2))]\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.transform:\n",
    "            image = self.transform(self.imgs[idx])\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(self.img_labels[idx])\n",
    "        return image, label\n",
    "    \n",
    "mean = torch.reshape(torch.tensor([0.485, 0.456, 0.406]),(3,1,1)).cuda()\n",
    "std = torch.reshape(torch.tensor([0.229, 0.224, 0.225]),(3,1,1)).cuda()\n",
    "transform = T.Compose([T.Resize([224,224]),T.ToTensor(),T.Normalize(mean,std)])  \n",
    "\n",
    "def resample(sample,factor):\n",
    "    n = len(sample)\n",
    "    if factor>1: #upsample\n",
    "        extra = int((factor-1)*n)\n",
    "        new_samples = torch.zeros((extra,)+sample.size()[1:])\n",
    "        for e in range(extra):\n",
    "            i = np.random.randint(n)\n",
    "            new_samples[e] = samples[i]\n",
    "        return torch.cat([sample,new_samples])\n",
    "    else: #downsample\n",
    "        remain, seen = int(factor*n), set()\n",
    "        remain_samples = torch.zeros((remain,)+sample.size()[1:])\n",
    "        for r in range(remain):\n",
    "            i = np.random.randint(n)\n",
    "            add = 1\n",
    "            while i in seen:\n",
    "                i = (i+add)%n\n",
    "                add *= 2\n",
    "            seen.add(i)\n",
    "            remain_samples[r] = sample[i]\n",
    "        return remain_samples  \n",
    "\n",
    "train_ds = BinaryDataset(train_cats,train_dogs,transform=transform)\n",
    "#train_ds = BinaryDataset(resample(train_cats,0.2),train_dogs,transform=transform)\n",
    "#train_ds = BinaryDataset(train_cats,resample(train_dogs,5),transform=transform)\n",
    "test_ds = BinaryDataset(test_cats,test_dogs,transform=transform)\n",
    "train_loader = DataLoader(train_ds, batch_size = 100, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size = 100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, loader, num_epochs=20):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=4*1e-3)\n",
    "    loss_module = nn.CrossEntropyLoss()\n",
    "    #loss_module = nn.CrossEntropyLoss(weight=torch.tensor([1,5])) #importance weighting:[1,5]\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"at epoch \", epoch)\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        total_loss = 0\n",
    "        for X, y in loader:\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "            yp = model(X)\n",
    "            loss = loss_module(yp, y)\n",
    "            total_loss += loss.item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.mean().backward()\n",
    "            optimizer.step()\n",
    "            correct += (yp.max(dim=1)[1] == y).sum()\n",
    "            total += len(X)\n",
    "        print(correct.item(),\" out of  \", total)\n",
    "        print(\"loss is \", total_loss)\n",
    "            \n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
